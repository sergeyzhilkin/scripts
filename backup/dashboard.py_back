import boto3

#buckets total count
cloudwatch = boto3.client('cloudwatch', region_name='us-east-2')
s3client=boto3.client('s3', region_name='us-east-2')
buckets_count=  len(s3client.list_buckets()['Buckets'])

response = cloudwatch.put_metric_data(
    Namespace='Custom metrics',
    MetricData=[
        {
            'MetricName': 'Buckets-total-count',
            'Dimensions': [
                {
                    'Name': 'S3 Buckets',
                    'Value': 'all buckets'
                },
            ],
            'Value': float(buckets_count),
            'StorageResolution': 60
        },
    ]
)

#get size, name, object_num  of every bucket, store to size_dict, object_dict
from datetime import datetime, timedelta
seconds_in_one_day = 86400  # used for granularity
size_dict={}
object_dict={}
for bucket in s3client.list_buckets()["Buckets"]:
  bucket_name = bucket['Name']  #s3client.list_buckets()['Buckets'][i1]['Name']
  bucket_size = cloudwatch.get_metric_statistics(
    Namespace='AWS/S3',
    Dimensions=[
        {
            'Name': 'BucketName',
            'Value': bucket_name
        },
        {
            'Name': 'StorageType',
            'Value': 'StandardStorage'
        }
    ],
    MetricName='BucketSizeBytes',
    StartTime=datetime.now() - timedelta(days=1),
    EndTime=datetime.now(),
    Period=seconds_in_one_day,
    Statistics=[
        'Average'
    ],
    Unit='Bytes'
  )

  bucket_object = cloudwatch.get_metric_statistics(
    Namespace='AWS/S3',
    Dimensions=[
        {
            'Name': 'BucketName',
            'Value': bucket_name
        },
        {
            'Name': 'StorageType',
            'Value': 'AllStorageTypes'
        }
    ],
    MetricName='NumberOfObjects',
    StartTime=datetime.now() - timedelta(days=1),
    EndTime=datetime.now(),
    Period=seconds_in_one_day,
    Statistics=[
        'Average'
    ],
    Unit='Count'
  )

  if bucket_size['Datapoints']:
   size_dict[bucket_name]= bucket_size['Datapoints'][0]['Average']
  if bucket_object['Datapoints']:
   object_dict[bucket_name]=bucket_object['Datapoints'][0]['Average']
   #if bucket_object['Datapoints'][0]['Average'] == 26.0:
   # object_dict[bucket_name]=1.0

#save names of buckets sorted by size to sort_size_list
sort_size_list=[]
listik =[]
for n in size_dict:
  listik.append(float(size_dict[n]))
listik.sort(reverse=True)
for i in range(len(size_dict)):
 for n in size_dict:
  if float(size_dict[n])==listik[i]:
   if n not in sort_size_list: 
    sort_size_list.append(n)

#save names pf buckets sorted by object count to sort_object_list
listik =[]
sort_object_list=[]
for n in object_dict:
  listik.append(float(object_dict[n]))
listik.sort(reverse=True)
for i in range(len(object_dict)):
 for n in object_dict:
  if float(object_dict[n])==listik[i]:
   if n not in sort_object_list: 
    sort_object_list.append(n) #list can contain more then 3 elements (if several buckets have the same number of objects)

"""
#upload not null bucket sizes to CloudWatch
for bucket2 in size_dict:
 response = cloudwatch.put_metric_data(
    Namespace='Custom metrics',
    MetricData=[
        {
            'MetricName': 'BucketSize',
            'Dimensions': [
                {
                    'Name': 'S3 Buckets',
                    'Value': bucket2
                },
            ],
            'Unit': 'Bytes',
            'Value': size_dict[bucket2],
            'StorageResolution': 60
        },
    ]
 )

response = cloudwatch.get_dashboard(
    DashboardName='s3-dashboard'
)
print response

#put dashboard with total count and 3 largest buckets to CloudWatch
response = cloudwatch.put_dashboard(
   DashboardName = 's3-dashboard',
   DashboardBody = '{"widgets":[{"type":"metric","x":10,"y":0,"width":6,"height":3,"properties":{"metrics":[["Custom metrics","Buckets-total-count","S3 Buckets","all buckets",{"period":3600,"label":"Buckets total"}]],"view":"singleValue","stacked":false,"region":"us-east-2","title":"Buckets total"}},{"type":"metric","x":0,"y":0,"width":10,"height":5,"properties":{"metrics":[["Custom metrics","BucketSize","S3 Buckets","' + sort_size_dict[0] + '",{"period":3600}],["...","' + sort_size_dict[1] + '",{"period":3600}],["...","' + sort_size_dict[2] + '",{"period":3600}]],"view":"timeSeries","stacked":false,"region":"us-east-2","legend":{"position":"right"},"title":"Top 3 Buckets (size)"}}]}' 
)
"""

response = cloudwatch.put_dashboard(
   DashboardName = 's3-dashboard',
   DashboardBody = '{"widgets":[{"type":"metric","x":12,"y":0,"width":6,"height":3,"properties":{"metrics":[["Custom metrics","Buckets-total-count","S3 Buckets","all buckets",{"period":3600,"label":"Buckets total"}]],"view":"singleValue","stacked":false,"region":"us-east-2","title":"Buckets total"}},{"type":"metric","x":0,"y":0,"width":12,"height":6,"properties":{"view":"timeSeries","stacked":false,"region":"us-east-2","metrics":[["AWS/S3","BucketSizeBytes","StorageType","StandardStorage","BucketName","' + sort_size_list[0] + '",{"period":86400}],["...","' + sort_size_list[1] + '",{"period":86400}],["...","' + sort_size_list[2] + '",{"period":86400}]],"start":"-P3D","end":"P0D","legend":{"position":"right"},"title":"BucketSizeBytes"}},{"type":"metric","x":0,"y":6,"width":12,"height":6,"properties":{"view":"timeSeries","stacked":false,"metrics":[["AWS/S3","NumberOfObjects","StorageType","AllStorageTypes","BucketName","' + sort_object_list[0] + '",{"period":86400}],["...","' + sort_object_list[1] + '",{"period":86400}],["...","' + sort_object_list[2] + '",{"period":86400}]],"region":"us-east-2","legend":{"position":"right"}}}]}'
)

#print sort_object_list[0],sort_object_list[1],sort_object_list[2]
#print sort_size_list[0],sort_size_list[1],sort_size_list[2]
